import torch
import torch.nn as nn
import torch.optim as optim
import random
import matplotlib.pyplot as plt

# Device Config
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Running on: {device}")

# ==========================================
# 1. DECIMAL DATA GENERATOR
# ==========================================
def generate_decimal_batch(batch_size, length):
    X, Y = [], []
    
    # We always define the sequence length as N + 1
    # This guarantees space for the final carry.
    seq_len = length + 1
    
    for _ in range(batch_size):
        # 1. Generate random numbers of 'length' digits
        # e.g., if length=2, max is 99.
        max_val = (10 ** length) - 1
        a = random.randint(0, max_val)
        b = random.randint(0, max_val)
        c = a + b # Real sum (e.g., 99+99=198)
        
        # 2. Extract digits for the FULL sequence (length + 1)
        # We grab digits 0 to 'length'.
        # If the number is small (e.g. 50+20=70), the last digit will naturally be 0.
        a_seq = [(a // (10**i)) % 10 for i in range(seq_len)]
        b_seq = [(b // (10**i)) % 10 for i in range(seq_len)]
        c_seq = [(c // (10**i)) % 10 for i in range(seq_len)]
        
        # 3. Stack inputs
        # The last position of input will always be [0, 0]
        # The AI sees this and thinks "Ah, a blank space for me to write the carry."
        x_seq = [[d_a, d_b] for d_a, d_b in zip(a_seq, b_seq)]
        
        X.append(x_seq)
        Y.append(c_seq)
        
    return torch.tensor(X).long().to(device), torch.tensor(Y).long().to(device)

# ==========================================
# 2. STANDARD DECIMAL TRANSFORMER
# ==========================================
class StandardDecimalTransformer(nn.Module):
    def __init__(self, d_model, nhead, num_layers=4, max_len=100):
        super().__init__()
        # Embedding for digits 0-9
        self.digit_embedding = nn.Embedding(10, d_model)
        
        # Absolute Positional Encoding
        self.pos_embedding = nn.Parameter(torch.randn(1, max_len, d_model) * 0.1)
        
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True, norm_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # Output 10 classes (digits 0-9)
        self.output_head = nn.Linear(d_model, 10)

    def forward(self, x, num_loops=None):
        seq_len = x.shape[1]
        
        # Embed the two input digits separately and sum them
        # x[:,:,0] is digit A, x[:,:,1] is digit B
        emb_a = self.digit_embedding(x[:,:,0])
        emb_b = self.digit_embedding(x[:,:,1])
        h = emb_a + emb_b # Combine
        
        # Add position
        h = h + self.pos_embedding[:, :seq_len, :]
        
        h = self.transformer(h)
        return self.output_head(h)

# ==========================================
# 3. LOOPED DECIMAL TRANSFORMER
# ==========================================
class LoopedDecimalTransformer(nn.Module):
    def __init__(self, d_model, nhead, max_relative_dist=4):
        super().__init__()
        self.digit_embedding = nn.Embedding(10, d_model)
        
        # Relative Bias
        self.max_relative_dist = max_relative_dist
        self.relative_bias_table = nn.Parameter(torch.Tensor(1, nhead, 2 * max_relative_dist + 1))
        nn.init.xavier_uniform_(self.relative_bias_table)
        
        self.shared_layer = nn.TransformerEncoderLayer(
            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4, batch_first=True, norm_first=True
        )
        self.output_head = nn.Linear(d_model, 10)
        self.input_gate = nn.Parameter(torch.tensor(0.1))

    def get_relative_bias(self, seq_len, device):
        range_vec = torch.arange(seq_len, device=device)
        distance_mat = range_vec[None, :] - range_vec[:, None]
        distance_mat_clamped = torch.clamp(distance_mat, -self.max_relative_dist, self.max_relative_dist)
        final_indices = distance_mat_clamped + self.max_relative_dist
        bias = self.relative_bias_table[0, :, final_indices.long()]
        causal_mask = torch.triu(torch.full((seq_len, seq_len), float('-inf'), device=device), diagonal=1)
        return bias + causal_mask.unsqueeze(0)

    def forward(self, x, num_loops=None):
        B, seq_len, _ = x.shape
        if num_loops is None:
            num_loops = seq_len + 5

        # Embed Inputs
        emb_a = self.digit_embedding(x[:,:,0])
        emb_b = self.digit_embedding(x[:,:,1])
        input_emb = emb_a + emb_b
        h = input_emb.clone()
        
        relative_bias = self.get_relative_bias(seq_len, x.device)
        attn_mask = relative_bias.repeat(B, 1, 1)

        for _ in range(num_loops):
            h_new = self.shared_layer(h, src_mask=attn_mask)
            h = h_new + (self.input_gate * input_emb)
            
        return self.output_head(h)

# ==========================================
# 4. TRAINING & PLOTTING
# ==========================================
def train_and_compare():
    D_MODEL = 128 # Slightly larger for decimal complexity
    NHEAD = 4
    
    # 1. Setup Models
    std_model = StandardDecimalTransformer(D_MODEL, NHEAD, num_layers=4).to(device)
    loop_model = LoopedDecimalTransformer(D_MODEL, NHEAD, max_relative_dist=4).to(device) # Window=4
    
    optimizers = {
        "Standard": optim.Adam(std_model.parameters(), lr=0.001),
        "Looped": optim.Adam(loop_model.parameters(), lr=0.001)
    }
    
    criterion = nn.CrossEntropyLoss()
    
    print("--- Training Phase (8-Digit Numbers) ---")
    # Train both for 2000 steps
    for step in range(2001):
        X, Y = generate_decimal_batch(64, length=8)
        
        # Train Standard
        opt = optimizers["Standard"]
        opt.zero_grad()
        out = std_model(X)
        loss_std = criterion(out.reshape(-1, 10), Y.reshape(-1))
        loss_std.backward()
        opt.step()
        
        # Train Looped
        opt = optimizers["Looped"]
        opt.zero_grad()
        out = loop_model(X, num_loops=12) # 8 digits + buffer
        loss_loop = criterion(out.reshape(-1, 10), Y.reshape(-1))
        loss_loop.backward()
        opt.step()
        
        if step % 500 == 0:
            print(f"Step {step}: Std Loss {loss_std.item():.3f} | Loop Loss {loss_loop.item():.3f}")

    print("\n--- Generalization Test (Length 8 to 24) ---")
    lengths = [8, 12, 16, 20, 24]
    std_accs = []
    loop_accs = []
    
    for L in lengths:
        with torch.no_grad():
            X_test, Y_test = generate_decimal_batch(100, length=L)
            
            # Test Standard
            out_std = std_model(X_test)
            acc_s = (out_std.argmax(-1) == Y_test).float().mean().item()
            std_accs.append(acc_s)
            
            # Test Looped (Scale loops with length)
            out_loop = loop_model(X_test, num_loops=L + 5)
            acc_l = (out_loop.argmax(-1) == Y_test).float().mean().item()
            loop_accs.append(acc_l)
            
    # Print Table
    print(f"{'Length':<10} | {'Standard Acc':<15} | {'Looped Acc':<15}")
    print("-" * 45)
    for i, L in enumerate(lengths):
        print(f"{L:<10} | {std_accs[i]:.2f}{'':<11} | {loop_accs[i]:.2f}")

    # Plot
    plt.figure(figsize=(8, 5))
    plt.plot(lengths, std_accs, 'r-o', label='Standard (Memorization)')
    plt.plot(lengths, loop_accs, 'g-o', label='Looped (Abstraction)')
    plt.axvline(x=8, color='gray', linestyle='--', label='Training Cutoff')
    plt.title("Decimal Addition: Generalization to Long Numbers")
    plt.xlabel("Number of Digits")
    plt.ylabel("Accuracy")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

train_and_compare()